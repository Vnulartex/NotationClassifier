{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qhXdKqfi80Dt"
   },
   "outputs": [],
   "source": [
    "from music21 import *\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import svm, naive_bayes, neighbors\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "import data_loader as loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading unprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "RPWbGTiA2g3_",
    "outputId": "2fbf29aa-2f20-4fed-98a4-91796b0a466f"
   },
   "outputs": [],
   "source": [
    "def fit(x_train,y_train, x_test, y_test,classifiers):\n",
    "    for clf in classifiers:\n",
    "        clf.fit(x_train,y_train)\n",
    "        print(clf)\n",
    "        print(f\"acc: {clf.score(x_test,y_test)}\",\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_k(x_train,y_train, x_test, y_test):\n",
    "    best_acc = 0\n",
    "    k = 0\n",
    "    for i in range(1,60):\n",
    "        k_nn = neighbors.KNeighborsClassifier(n_neighbors=i)\n",
    "        k_nn.fit(x_train, y_train)\n",
    "        acc = k_nn.score(x_test,y_test)\n",
    "        if(acc>best_acc):\n",
    "            best_acc = acc\n",
    "            k = i\n",
    "    print(f\"best k = {k}, best acc = {best_acc}\")\n",
    "    return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_ngrams(x_train,y_train,x_test,y_test,n):\n",
    "    print(\"n =\",n)\n",
    "    \n",
    "    ngram_vectorizer = CountVectorizer(token_pattern=\"\\d+\", ngram_range=(1, n))\n",
    "    ngrams_train = ngram_vectorizer.fit_transform(x_train)\n",
    "    ngrams_test = ngram_vectorizer.transform(x_test)\n",
    "\n",
    "    print(\"train shape =\", ngrams_train.shape,len(y_train))\n",
    "    print(\"test shape =\", ngrams_test.shape,len(y_test))\n",
    "    \n",
    "    k = find_k(ngrams_train,y_train,ngrams_test,y_test)\n",
    "    fit(ngrams_train,y_train,ngrams_test,y_test,\n",
    "         [neighbors.KNeighborsClassifier(n_neighbors=k), naive_bayes.MultinomialNB()])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "composerNames = [\"debussy\",\"tchaikovsky\",\"mozart\",\"victoria\",\"beethoven\"]\n",
    "#count = min(loader.get_data_counts(composerNames))\n",
    "x_train, x_test,y_train, y_test = loader.load(\"chords\",composerNames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'debussy': 119, 'tchaikovsky': 165, 'mozart': 423, 'victoria': 188, 'beethoven': 380} {'debussy': 40, 'tchaikovsky': 54, 'mozart': 124, 'victoria': 61, 'beethoven': 61}\n"
     ]
    }
   ],
   "source": [
    "print(loader.get_data_counts(y_train,composerNames),loader.get_data_counts(y_test,composerNames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitches_train = [str([chord[0] for chord in example])for example in x_train]\n",
    "pitches_test = [str([chord[0] for chord in example])for example in x_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 5, 10, 2, 5, 7, 9, 4, 12, 9, 4, 12, 10, 2, 7, 10, 2, 4, 5, 12, 9, 5, 12, 9, 7, 10, 2, 2, 2, 7, 10, 7, 10, 5, 10, 2, 2, 2, 7, 10, 2, 10, 4, 10, 2, 2, 2, 7, 10, 7, 10, 2, 10, 5, 10, 5, 10, 2, 10, 12, 7, 10, 10, 2, 4, 7, 10, 2, 4, 10, 2, 9, 12, 7, 10, 5, 12, 5, 5, 7, 9, 2, 5, 12, 12, 9, 2, 9, 5, 12, 12, 7, 9, 5, 5, 2, 9, 4, 5, 9, 2, 9, 2, 5, 2, 12, 5, 12, 5, 5, 7, 9, 2, 5, 12, 12, 9, 2, 9, 5, 12, 12, 7, 9, 5, 5, 2, 9, 4, 5, 9, 2, 9, 2, 5, 2, 12, 7, 10, 2, 12, 2, 5, 7, 2, 10, 5, 7, 4, 5, 5, 2, 2, 9, 2, 9, 5, 9, 12, 9, 5, 5, 2, 4, 10, 2, 5, 4, 5, 7, 10, 5, 2, 9, 10, 7, 7, 9, 5, 5, 11, 5, 2, 9, 2, 2, 7, 11, 11, 2, 5, 11, 9, 5, 11, 5, 2, 9, 7, 2, 2, 5, 5, 11, 2, 9, 11, 5, 9, 7, 2, 9, 2, 7, 11, 7, 5, 9, 11, 5, 9, 7, 2, 9, 2, 7, 7, 11, 9, 5, 10, 2, 5, 10, 2, 5, 7, 9, 4, 12, 9, 4, 12, 7, 10, 2, 7, 10, 2, 4, 5, 12, 9, 5, 12, 9, 4, 8, 2, 4, 11, 4, 2, 5, 9, 2, 5, 9, 12, 5, 12, 2, 4, 8, 2, 4, 11, 4, 2, 4, 5, 10, 2, 2, 5, 9, 2, 9, 10, 12, 4, 10, 12, 7, 12, 10, 12, 2, 7, 10, 10, 2, 5, 10, 5, 7, 9, 1, 7, 9, 4, 9, 7, 2, 10, 7, 2, 10, 5, 5, 9, 10, 7, 7, 4, 1, 7, 9, 9, 4, 9, 7, 12, 7, 7, 10, 10, 3, 10, 2, 7, 5, 12, 5, 9, 3, 9, 5, 12, 7, 7, 10, 10, 2, 3, 5, 10, 3, 7, 9, 12, 5, 9, 7, 3, 9, 5, 5, 12, 5, 3, 7, 9, 12, 2, 10, 10, 5, 8, 10, 10, 12, 10, 5, 8, 10, 12, 10, 2, 8, 10, 2, 5, 2, 7, 3, 10, 10, 7, 12, 2, 12, 10, 12, 2, 12, 10, 7, 2, 12, 12, 7, 7, 10, 10, 4, 12, 4, 12, 9, 9, 9, 5, 9, 12, 5, 12, 5, 2, 10, 7, 7, 2, 5, 7, 10, 2, 5, 7, 10, 9, 7, 2, 10, 5, 7, 9, 4, 10, 2, 2, 10, 7, 7, 2, 5, 7, 10, 2, 5, 7, 10, 9, 7, 2, 10, 5, 10, 7, 2, 5, 12, 9, 7, 4, 7, 2, 10, 5, 9, 4, 12, 12, 7, 10, 5, 2, 7, 9, 12, 7, 4, 10, 10, 2, 9, 5, 12, 12, 4, 10, 7, 4, 2, 5, 12, 9, 7, 4, 7, 2, 10, 10, 5, 9, 4, 12, 12, 7, 10, 7, 9, 5, 5, 12, 5, 5, 9, 12, 5, 9, 5, 5, 5, 10, 7, 12, 3, 2, 5, 2, 3, 2, 12, 12, 9, 5, 2, 7, 7, 4, 7, 12, 9, 7, 9, 5, 5, 12, 7, 7, 9, 5, 5, 10, 7, 10, 10, 9, 10, 10, 9, 12, 10, 7, 5, 10, 7, 12, 3, 2, 5, 2, 3, 2, 12, 12, 9, 6, 2, 10, 5, 7, 7, 12, 4, 7, 7, 2, 4, 9, 12, 5, 5, 12, 10, 7, 10, 12, 5, 10, 5, 9, 5, 5, 3, 7, 10, 2, 7, 12, 10, 9, 12, 3, 7, 5, 5, 3, 2, 5, 9, 12, 10, 10, 9, 7, 10, 2, 5, 3, 3, 2, 12, 3, 7, 10, 12, 12, 12, 9, 7, 9, 5, 5, 7, 10, 10, 5, 3, 5, 2, 3, 10, 7, 2, 5, 12, 3, 10, 2, 3, 7, 10, 2, 7, 12, 10, 9, 12, 3, 7, 5, 5, 3, 2, 5, 9, 12, 10, 10, 9, 7, 10, 2, 5, 3, 3, 2, 12, 3, 7, 10, 12, 12, 12, 9, 7, 9, 12, 3, 7, 10, 3, 12, 12, 9, 7, 9, 5, 9, 3, 5, 3, 5, 2, 7, 7, 12, 12, 6, 9, 2, 10, 5, 10, 7, 4, 12, 9, 7, 9, 5, 5, 12, 7, 7, 9, 5, 5, 10, 7, 10, 10, 9, 10, 10, 9, 12, 10, 7, 10, 7, 12, 3, 2, 10, 10, 2, 3, 2, 12, 9, 12, 6, 2, 10, 5, 7, 9, 4, 12, 7, 7, 2, 4, 9, 12, 5, 5, 12, 10, 7, 10, 12, 5, 10, 5, 5, 5, 5, 8, 8, 5, 6, 8, 10, 6, 3, 6, 1, 10, 8, 6, 1, 10, 3, 6, 6, 10, 8, 5, 10, 6, 3, 6, 12, 6, 8, 8, 3, 6, 6, 8, 12, 3, 6, 8, 5, 6, 8, 1, 5, 10, 3, 5, 11, 6, 10, 8, 8, 5, 6, 8, 1, 5, 8, 9, 9, 5, 1, 9, 1, 5, 2, 9, 5, 4, 10, 2, 5, 10, 2, 5, 7, 9, 4, 12, 9, 4, 12, 7, 10, 2, 7, 10, 2, 4, 5, 12, 9, 5, 12, 9, 7, 10, 2, 2, 2, 7, 10, 7, 10, 5, 10, 2, 2, 2, 7, 10, 2, 10, 4, 10, 2, 2, 2, 7, 10, 7, 10, 2, 10, 5, 10, 5, 10, 2, 12, 7, 10, 10, 2, 4, 7, 10, 2, 4, 10, 2, 9, 12, 7, 10, 5, 12, 5, 5, 7, 9, 2, 5, 12, 12, 9, 2, 9, 5, 12, 12, 7, 9, 5, 5, 2, 9, 4, 5, 9, 2, 9, 2, 5, 2, 12, 5, 12, 5, 5, 7, 9, 2, 5, 12, 12, 9, 2, 9, 5, 12, 12, 7, 9, 5, 5, 2, 9, 4, 5, 9, 2, 9, 2, 5, 2, 12, 7, 10, 2, 12, 2, 5, 7, 2, 10, 5, 7, 4, 5, 5, 2, 2, 9, 2, 9, 5, 9, 12, 9, 5, 5, 2, 4, 10, 2, 5, 4, 5, 7, 10, 5, 2, 9, 10, 7, 7, 9, 5, 5, 11, 5, 2, 9, 2, 2, 7, 11, 11, 2, 5, 11, 9, 5, 11, 5, 2, 9, 7, 2, 2, 5, 5, 11, 2, 9, 11, 5, 9, 7, 2, 9, 2, 7, 11, 7, 5, 9, 11, 5, 9, 7, 2, 9, 2, 7, 7, 11, 9, 5, 10, 2, 5, 10, 2, 5, 7, 9, 4, 12, 9, 4, 12, 7, 10, 2, 7, 10, 2, 4, 5, 12, 9, 5, 12, 9, 10, 2, 5, 10, 12, 5, 2, 10, 2, 5, 10, 12, 4, 9, 9, 10, 4, 12, 9, 7, 4, 7, 2, 10, 2, 7, 7, 10, 7, 2, 12, 9, 12, 5, 5, 9, 5, 12, 5, 7, 10, 3, 3, 5, 10, 7, 3, 7, 10, 3, 5, 9, 2, 2, 3, 9, 5, 2, 2, 9, 2, 7, 3, 7, 12, 12, 3, 12, 7, 5, 2, 5, 10, 10, 2, 10, 5, 10, 3, 12, 6, 9, 9, 10, 12, 9, 9, 6, 2, 2, 10, 2, 10, 7, 7, 10, 7, 2, 7, 12, 9, 12, 5, 5, 7, 9, 5, 5, 12, 10, 7, 2, 5, 7, 10, 12, 2, 5, 10, 12, 10, 2, 5, 10, 12, 2, 5, 2, 12, 10, 5, 2, 12, 10, 5, 9, 12, 12, 4, 9, 12, 4, 9, 12, 4, 9, 12, 12, 7, 12, 12, 4, 10, 12, 4, 10, 12, 4, 10, 12, 12, 5, 5, 12, 5, 5, 7, 9, 2, 5, 12, 12, 9, 2, 9, 5, 12, 12, 7, 9, 5, 5, 2, 9, 4, 5, 9, 2, 9, 2, 5, 2, 12, 5, 12, 5, 5, 7, 9, 2, 5, 12, 12, 9, 2, 9, 5, 12, 12, 7, 9, 5, 5, 2, 9, 4, 5, 9, 2, 9, 2, 5, 2, 5, 12, 5, 12, 2, 9, 5, 5, 12, 9, 7, 2, 5, 12, 5, 12, 2, 9, 5, 5, 12, 9, 7, 2, 5, 12, 5, 12, 2, 9, 5, 5, 12, 9, 7, 2, 5, 5, 5, 5, 5, 5, 5, 5]\n"
     ]
    }
   ],
   "source": [
    "print(pitches_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 1\n",
      "train shape = (1275, 30) 1275\n",
      "test shape = (340, 30) 340\n",
      "best k = 23, best acc = 0.5970588235294118\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=23, p=2,\n",
      "           weights='uniform')\n",
      "acc: 0.5970588235294118 \n",
      "\n",
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "acc: 0.5323529411764706 \n",
      "\n",
      "n = 2\n",
      "train shape = (1275, 238) 1275\n",
      "test shape = (340, 238) 340\n",
      "best k = 18, best acc = 0.6088235294117647\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=18, p=2,\n",
      "           weights='uniform')\n",
      "acc: 0.6088235294117647 \n",
      "\n",
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "acc: 0.5411764705882353 \n",
      "\n",
      "n = 3\n",
      "train shape = (1275, 1385) 1275\n",
      "test shape = (340, 1385) 340\n",
      "best k = 16, best acc = 0.6235294117647059\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=16, p=2,\n",
      "           weights='uniform')\n",
      "acc: 0.6235294117647059 \n",
      "\n",
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "acc: 0.538235294117647 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n in range(1,4):\n",
    "    fit_ngrams(pitches_train,y_train,pitches_test,y_test,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_vectorizer = CountVectorizer(token_pattern=\"\\d+\", ngram_range=(1,3))\n",
    "bigrams_train = bigram_vectorizer.fit_transform(pitches_train)\n",
    "bigrams_test = bigram_vectorizer.fit_transform(pitches_test)\n",
    "\n",
    "print(bigrams_train.shape)\n",
    "k = find_k(bigrams_train,y_train,bigrams_test,y_test)\n",
    "fit(bigrams_train,y_train,bigrams_test,y_test,\n",
    "     [neighbors.KNeighborsClassifier(n_neighbors=k), naive_bayes.MultinomialNB()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 705
    },
    "colab_type": "code",
    "id": "kX9NVmN1KtcC",
    "outputId": "b4d52e82-a7be-4c22-98a4-75f258de4d22"
   },
   "outputs": [],
   "source": [
    "classes = list(set(y_test))\n",
    "test_data = list(zip(x_test,y_test))\n",
    "for label in classes:\n",
    "    label_data = [tupple[0] for tupple in test_data if tupple[1] == label][:10]\n",
    "    plt.plot(label_data)\n",
    "    plt.xlabel(\"Examples\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Note pitches",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
