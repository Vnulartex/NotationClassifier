{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "qhXdKqfi80Dt"
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pickle\n",
    "import numpy as np\n",
    "from music21 import *\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import svm, naive_bayes, neighbors\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import data_loader as loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "RPWbGTiA2g3_",
    "outputId": "2fbf29aa-2f20-4fed-98a4-91796b0a466f"
   },
   "outputs": [],
   "source": [
    "def fit(x_train,y_train, x_test, y_test,classifiers):\n",
    "    for clf in classifiers:\n",
    "        clf.fit(x_train,y_train)\n",
    "        print(clf)\n",
    "        print(f\"acc: {clf.score(x_test,y_test)}\",\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_k(x_train,y_train, x_test, y_test):\n",
    "    best_acc = 0\n",
    "    k = 0\n",
    "    for i in range(1,30):\n",
    "        k_nn = neighbors.KNeighborsClassifier(n_neighbors=i)\n",
    "        k_nn.fit(x_train, y_train)\n",
    "        acc = k_nn.score(x_test,y_test)\n",
    "        if(acc>best_acc):\n",
    "            best_acc = acc\n",
    "            k = i\n",
    "    print(f\"best k = {k}, best acc = {best_acc}\")\n",
    "    return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_ngrams(x_train,y_train,x_test,y_test,n):    \n",
    "    ngrams_train, ngrams_test = ngrams_vectorize(x_train, x_test,n)\n",
    "    \n",
    "    k = find_k(ngrams_train,y_train,ngrams_test,y_test)\n",
    "    fit(ngrams_train,y_train,ngrams_test,y_test,\n",
    "         [neighbors.KNeighborsClassifier(n_neighbors=k), naive_bayes.MultinomialNB(),svm.LinearSVC(dual=False)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ngrams_vectorize(x_train,x_test,n):\n",
    "    print(\"n =\",n)\n",
    "    \n",
    "    ngram_vectorizer = CountVectorizer(token_pattern=\"\\d+\", ngram_range=(1, n))\n",
    "    ngrams_train = ngram_vectorizer.fit_transform(x_train)\n",
    "    ngrams_test = ngram_vectorizer.transform(x_test)\n",
    "\n",
    "    print(\"train shape =\", ngrams_train.shape)\n",
    "    print(\"test shape =\", ngrams_test.shape)\n",
    "    \n",
    "    return ngrams_train, ngrams_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine(x1,x2,x1_classes):\n",
    "    result =[]\n",
    "    for a,b in zip (x1,x2):\n",
    "        result.append(x1_classes * b + a)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine_item(x1,x2,x1_classes):\n",
    "    return x1_classes * x2 + x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unique_dict(in_list):\n",
    "    dic = dict.fromkeys(in_list)\n",
    "    for i,k in enumerate(dic.keys()):\n",
    "        dic[k]=i\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def values_to_labels(in_list,dic):\n",
    "    out_list = [dic[x] for x in in_list]\n",
    "    return out_list        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stringify_items(in_list):\n",
    "    return [str(x) for x in in_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define known chords\n",
    "chords_list = ([0], [0,4,7],[0,3,7],[0,5,7],[0,4,8],[0,3,6],[0,4,7,9],[0,3,7,9],\n",
    "[0,4,7,10],[0,4,7,11],[0,3,7,10],[0,3,6,10],[0,3,6,9],[0,2,4,7,11],\n",
    "[0,2,4,7,10],[0,1,4,7,10],[0,2,3,7,10])\n",
    "\n",
    "# chord_types_list = [tone,major, minor, suspended, augmented, \n",
    "#                     diminished, major_sixth, minor_sixth, \n",
    "#                     dominant_seventh, major_seventh, \n",
    "#                     minor_seventh, half_diminished_seventh, \n",
    "#                     diminished_seventh, major_ninth, \n",
    "#                     dominant_ninth, dominant_minor_ninth, minor_ninth]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_chord(in_list):\n",
    "    root = in_list[0]\n",
    "    if(len(in_list)==1):\n",
    "        return root\n",
    "    costs = []\n",
    "    for chord in chords_list:\n",
    "        cost = 0\n",
    "        for tone_p, tone_ch in itertools.zip_longest(in_list[1:],chord):\n",
    "            if(tone_p == None or tone_ch == None):\n",
    "                cost += 3\n",
    "            else:\n",
    "                cost+= abs(tone_p - tone_ch)\n",
    "        costs.append(cost)\n",
    "    i = list.index(costs,min(costs))\n",
    "    return combine_item(root,i,12)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading unprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "composerNames = [\"debussy\",\"tchaikovsky\",\"mozart\",\"victoria\",\"beethoven\"]\n",
    "dataset_type = \"chords_t\"\n",
    "x_train_ch, x_test_ch,y_train, y_test = loader.load(dataset_type,composerNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = [str([chord[0] for chord in example ]) for example in x_train_ch]\n",
    "x_test = [str([chord[0] for chord in example]) for example in x_test_ch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_d, x_test_d,y_train, y_test = loader.load(\"durations\",composerNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x_train = [str([find_chord(chord) for chord in example ]) for example in x_train_ch]\n",
    "# x_test = [str([find_chord(chord) for chord in example])for example in x_test_ch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pitches_seq = list(itertools.chain.from_iterable(x_train_ch+x_test_ch))\n",
    "# pitches_dict = unique_dict(pitches_seq)\n",
    "\n",
    "# x_train_ch = [values_to_labels(example,pitches_dict) for example in x_train_ch]\n",
    "# x_test_ch = [values_to_labels(example,pitches_dict) for example in x_test_ch]\n",
    "\n",
    "# durations_seq = list(itertools.chain.from_iterable(x_train_d+x_test_d))\n",
    "# durations_dict = unique_dict(durations_seq)\n",
    "\n",
    "# x_train_d = [values_to_labels(example,durations_dict) for example in x_train_d]\n",
    "# x_test_d = [values_to_labels(example,durations_dict) for example in x_test_d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x_train = list(map(str, combine(x_train_ch,x_train_d,len(pitches_dict))))\n",
    "# x_test = list(map(str, combine(x_test_ch,x_test_d,len(pitches_dict))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'debussy': 119, 'tchaikovsky': 165, 'mozart': 423, 'victoria': 188, 'beethoven': 380} {'debussy': 40, 'tchaikovsky': 54, 'mozart': 124, 'victoria': 61, 'beethoven': 61}\n"
     ]
    }
   ],
   "source": [
    "print(loader.get_data_counts(y_train,composerNames),loader.get_data_counts(y_test,composerNames))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 1\n",
      "train shape = (1275, 12)\n",
      "test shape = (340, 12)\n",
      "best k = 6, best acc = 0.65\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=6, p=2,\n",
      "           weights='uniform')\n",
      "acc: 0.65 \n",
      "\n",
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "acc: 0.6 \n",
      "\n",
      "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "acc: 0.6529411764705882 \n",
      "\n",
      "n = 2\n",
      "train shape = (1275, 156)\n",
      "test shape = (340, 156)\n",
      "best k = 2, best acc = 0.7176470588235294\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=2, p=2,\n",
      "           weights='uniform')\n",
      "acc: 0.7176470588235294 \n",
      "\n",
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "acc: 0.6588235294117647 \n",
      "\n",
      "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "acc: 0.7323529411764705 \n",
      "\n",
      "n = 3\n",
      "train shape = (1275, 1884)\n",
      "test shape = (340, 1884)\n",
      "best k = 2, best acc = 0.7176470588235294\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=2, p=2,\n",
      "           weights='uniform')\n",
      "acc: 0.7176470588235294 \n",
      "\n",
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "acc: 0.7147058823529412 \n",
      "\n",
      "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "acc: 0.7558823529411764 \n",
      "\n",
      "n = 4\n",
      "train shape = (1275, 22598)\n",
      "test shape = (340, 22598)\n",
      "best k = 1, best acc = 0.7147058823529412\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
      "           weights='uniform')\n",
      "acc: 0.7147058823529412 \n",
      "\n",
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "acc: 0.7558823529411764 \n",
      "\n",
      "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "acc: 0.7823529411764706 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train,y_train = loader.shuffle_data(x_train,y_train)\n",
    "x_test,y_test = loader.shuffle_data(x_test,y_test)\n",
    "\n",
    "for n in range(1,5):\n",
    "    fit_ngrams(x_train,y_train,x_test,y_test,n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape = (1275, 22598)\n",
      "test shape = (340, 22598)\n",
      "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "acc: 0.7823529411764706 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "ngram_vectorizer = CountVectorizer(token_pattern=\"\\d+\", ngram_range=(1, 4))\n",
    "ngrams_train = ngram_vectorizer.fit_transform(x_train)\n",
    "ngrams_test = ngram_vectorizer.transform(x_test)\n",
    "\n",
    "print(\"train shape =\", ngrams_train.shape)\n",
    "print(\"test shape =\", ngrams_test.shape)\n",
    "\n",
    "clf = svm.LinearSVC(dual=False)\n",
    "fit(ngrams_train, y_train,ngrams_test,y_test,[clf])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfobj = loader.Classifier(clf,composerNames,ngram_vectorizer, \"chords_t\",loader.get_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"models/svm_4grams.dat\",\"wb\") as f:\n",
    "    pickle.dump(clfobj,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# x,files = loader.load_folder(\"midis\",\"chords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 705
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "kX9NVmN1KtcC",
    "outputId": "b4d52e82-a7be-4c22-98a4-75f258de4d22"
   },
   "outputs": [],
   "source": [
    "# classes = list(set(y_test))\n",
    "# test_data = list(zip(x_test,y_test))\n",
    "# for label in classes:\n",
    "#     label_data = [tupple[0] for tupple in test_data if tupple[1] == label][:10]\n",
    "#     plt.plot(label_data)\n",
    "#     plt.xlabel(\"Examples\")\n",
    "#     plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Note pitches",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
